{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (with scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing required libraries\n",
    "\n",
    "Pandas library is used to read the data in a CSV format and store \n",
    "it as a DataFrame\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Scikit learn library contains functions to learn a model, predict\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading the CSV file into a DataFrame\n",
    "'''\n",
    "wdbc_data_path = \"./wdbc_data.csv\"\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "wdbc_data_df = pd.read_csv(wdbc_data_path, delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rearranging columns to make the datareadable by train_test_split\n",
    "'''\n",
    "\n",
    "target = wdbc_data_df[\"diagnosis\"]\n",
    "Y = [1 if i == 'M' else 0 for i in target] # Replacing 'M' by 1 & 'B' by 0\n",
    "\n",
    "del wdbc_data_df['id']\n",
    "del wdbc_data_df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Performing scaling to bring the values of the features to the same \n",
    "level of magnitude\n",
    "'''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(wdbc_data_df)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "full_df = pd.concat([X, Y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Splitting 20% of data for testing and the rest for training the model\n",
    "'''\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_splitt(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training a Logistic Regression model\n",
    "'''\n",
    "\n",
    "model = LogisticRegression(solver = \"liblinear\")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_predicted))\n",
    "print(confusion_matrix(Y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing required libraries\n",
    "'''\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Learning rate determines the rate at which the slope and intercept are\n",
    "learnt\n",
    "'''\n",
    "\n",
    "L = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    '''\n",
    "    This function is to load the wdbc.data into a Dataframe\n",
    "    '''\n",
    "    \n",
    "    pd.set_option(\"display.max_colwidth\", 50)\n",
    "    data = pd.read_csv(path, delimiter = \",\", encoding = \"utf-8\", header = None)\n",
    "    \n",
    "    Y = np.asarray([1 if i=='M' else 0 for i in data[1]])\n",
    "    \n",
    "    del data[0]\n",
    "    del data[1]\n",
    "    \n",
    "    X = feature_scaling(data)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y):\n",
    "    '''\n",
    "    This function is to perform logistic regression using gradient descent method\n",
    "    '''\n",
    "    \n",
    "    m = np.zeros(30)[np.newaxis]\n",
    "    c = 0\n",
    "    \n",
    "    Entropy = []\n",
    "    \n",
    "    for i in range(500):\n",
    "        Y_cap = np.add(np.matmul(X, m.T), np.array([c]))\n",
    "        \n",
    "        Entropy.append(((-1)/len(X))*(np.sum((Y * np.log(Y_cap)))+((1-Y)*(np.log(1-Y_cap)))))\n",
    "        \n",
    "        D_m = (-1)*(1/len(X))*(np.sum(X * np.subtract(Y, Y_cap)))\n",
    "        D_c = (-1)*(1/len(X))*(np.sum(np.subtract(Y, Y_cap)))\n",
    "        m = np.subtract(m, (np.multiply(L, D_m)))\n",
    "        c = np.subtract(c, (np.multiply(L, D_c)))\n",
    "        \n",
    "    return m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(data):\n",
    "    '''\n",
    "    This function is to scale the values of the features to the same\n",
    "    order of magnitude\n",
    "    '''\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, m, c):\n",
    "    '''\n",
    "    This function is to predict the value for Y from the given test input\n",
    "    '''\n",
    "    \n",
    "    Y_i = 1/(1 + np.exp(np.matmul(X, m.T) + c))\n",
    "    Y_i = np.asarray([1 if i > 0.5 else 0 for i in Y_i])[:, np.newaxis]\n",
    "    \n",
    "    return Y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(predicted_data, test_data):\n",
    "    '''\n",
    "    This function is to calculate the accuracy, precision, recall and\n",
    "    confusion matrix\n",
    "    '''\n",
    "    \n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for j in range(0, len(test_data)):\n",
    "        if(predicted_data[j] == 1 and test_data[j] == 1):\n",
    "            true_positive = true_positive + 1\n",
    "        elif(predicted_data[j] == 0 and test_data[j] == 1):\n",
    "            false_negative = false_negative + 1\n",
    "        elif(predicted_data[j] == 1 and test_data[j] == 0):\n",
    "            false_positive = false_positive + 1\n",
    "        elif(predicted_data[j] == 0 and test_data[j] == 0):\n",
    "            true_negative = true_negative + 1\n",
    "            \n",
    "    confusion_matrix = np.asarray([[true_positive, false_positive],[false_negative, true_negative]])\n",
    "\n",
    "    accuracy = ((true_positive + true_negative)/(true_positive + false_positive + false_negative + true_negative))*100\n",
    "    precision = (true_positive)/(true_positive + false_positive)\n",
    "    recall = (true_positive)/(true_positive + false_negative)\n",
    "\n",
    "    report = \"Accuracy : \"+str(round(accuracy, 2))+\"%\"+\"\\n\"+\"Precision : \"+str(round(precision, 3))+\"\\n\"+\"Recall : \"+str(round(recall, 3))+\"\\n\"\n",
    "\n",
    "    return report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Input/wdbc.data\"\n",
    "\n",
    "X, Y = get_data(data_path)\n",
    "\n",
    "X_train = X[:(math.ceil(len(X)*0.8))]\n",
    "Y_train = Y[:(math.ceil(len(Y)*0.8))][:, np.newaxis]\n",
    "\n",
    "X_test = X[(math.ceil(len(X)*0.8)):]\n",
    "Y_test = Y[(math.ceil(len(Y)*0.8)):][:, np.newaxis]\n",
    "\n",
    "slope, intercept = model(X_train, Y_train)\n",
    "\n",
    "Y_predict = predict(X_test, slope.flatten(), np.asscalar(intercept))\n",
    "\n",
    "report, confusion_matrix = metrics_report(Y_predict, Y_test)\n",
    "\n",
    "print(report)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondae982f1a592a4481480a41f9ab03bc2c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
